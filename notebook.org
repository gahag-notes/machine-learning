# -*- after-save-hook: org-latex-export-to-pdf; -*-
#+latex_header: \usepackage[margin=2cm]{geometry}
#+latex_header: \DeclareMathOperator{\sign}{sign}
#+latex_header: \setlength{\parindent}{0cm}
#+latex_header: \usepackage{pgfplots}
#+latex_header: \pgfplotsset{compat=1.11}
#+latex_header: \usetikzlibrary{arrows, decorations.markings}
#+latex_header: \usetikzlibrary{3d}
#+latex_header: \usetikzlibrary{shapes.geometric,decorations.fractals,shadows}

* Supervised learning
  Method where you train the program by feeding the learning algorithm with a mapping of
  inputs to correct outputs.
** Regression
   Regression is curve fitting: learn a continuous input $\to$ output mapping from a set of
   examples.
** Classification
   Outputs are discrete variables (category labels). Learn a decision boundary that
   separates one class from the other. Generally, a confidence is also desired, i.e.,
   how sure are we that the input belongs to the chosen category.
** Training set
   The training set is a set of $m$ $(X,\, y)$ pairs, where:
   #+begin_export latex
   \begin{align*}
     X \in \mathbb{R}^d & \quad\text{models the input.} \\
     y \in \{0, 1\} & \quad\text{models the output.}
   \end{align*}
   #+end_export
** Error function
   The error function for a model $f: X \mapsto y$ parameterized by $W$ applied to a
   dataset $\{ (X,\, y) \}$ of size $m$ is:
   #+begin_export latex
   \[
     \min_W \enspace \sum^m_{i=1}{ \big(f_W(X_i) - y_i \big)^2 }
   \]
   #+end_export
** Perceptron
   Perceptron is the trivial neural network. The model for a parameter $W = (\text{threshold},\,
   w_1,\, \hdots,\, w_d)$ and inputs of the form $(1,\, x_1,\, \hdots,\, x_d)$ is given by
   #+begin_export latex
   \[
     f_W(X) = \sign(W^{\top} X)
   \]
   #+end_export
   If $x_i$ is evidence for approval, then $w_i$ should be high. \\
   If $x_i$ is evidence for denial, then $w_i$ should be low.
*** Learning algorithm
    The learning algorithm of the Perceptron is quite simple. The learning rate $\in (0,\,
    1]$ is used to scale each step. the For a training set $S = \{ \, (X_1,\, y_1),\enspace (X_1,\,
    y_1),\enspace \hdots \, \}$
    - Starting with random weights, show each sample in sequence repetitively.
    - If the output is correct, do nothing.
    - If the produced output is negative, and the correct output is positive, increase the weights.
    - If the produced output is positive, and the correct output is negative, decrease the weights.
    - The amount to increase/decrease is given by the current sample scaled by the learning rate.
** Error
   The error function for a model $f$ in a *training* sample is
   #+begin_export latex
   \[ E_{\text{in}}(f) \]
   #+end_export
   This function is known and calculable.
   @@latex:\\[10pt]@@
   The error function for a model $f$ in a *test* sample is
   #+begin_export latex
   \[ E_{\text{ou}t}(f) \]
   #+end_export
   This function is *not* known, and only *approachable*.
   @@latex:\\[10pt]@@
   Given a model $f$ in a set of $M$ models, the bound for the probability of the error
   deviation surpassing a given $\epsilon$ is
   #+begin_export latex
   \[
     \mathbb{P}\left(\big| E_{\text{in}}(f) - E_{\text{ou}t}(f) \big| > \big\epsilon\right) \leq 2Me^{-2N\big\epsilon^2}
   \]
   #+end_export
   Notably, $E_{\text{in}}(f)$ and $E_{\text{out}}(f)$ deviates as $f$ becomes complex.
*** Empirical error minimization
    During the learning algorithm, always conserve the weights that produce the lower error. \\
    This has a disadvantage: It memorizes the training set.
** Ensemble learning
   Ensemble learning consists in combining several simple models to form a more complex
   model.
   - Bagging: :: Each model training with a different dataset
   - Boosting: :: Same dataset, but instrumented for each model to mitigate the weakness of
                 others
** Learning decision trees
   Each layer in the tree consists of an attribute that splits the data into subsets that
   are ideally disjoint. \\
   The entropy of the subsets produced is a measure of how disjoint they are.
   @@latex:\\[5pt]@@
   For a set containing $p$ positive and $n$ negatives, the entropy is
   #+begin_export latex
   \[
     H\left(\frac{p}{p+n}, \frac{n}{p+n} \right) = - \frac{p}{p + n} \log\left( \frac{p}{p + n} \right) 
                                                   - \frac{n}{p + n}\log\left( \frac{n}{p + n} \right)
   \]
   #+end_export
   A given attribute $A$, with $k$ distinct values, divides the training set $S$ into
   subsets $S_1, S_2, \hdots, S_k$. \\
   The expected entropy remaining after applying $A$ is
   #+begin_export latex
   \[
     EH(A) = \sum_{i = 1}^{k} \left[ \frac{p_i + n_i}{p + n} \cdot H\left( \frac{p_i}{p_i + n_i}, \frac{n_i}{p_i + n_i} \right) \right]
   \]
   #+end_export
   The information gain, i.e. the reduction in entropy for $A$, is
   #+begin_export latex
   \[
     I(A) = H\left( \frac{p}{p + n}, \frac{n}{p + n} \right) - EH(A)
   \]
   #+end_export
*** Capacity
    The capacity is a measure of when the training error is a good approximation for the
    test error.
    #+begin_export latex
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \begin{axis}[
            axis lines = middle,
            xlabel near ticks,
            ylabel near ticks,
            xlabel     = {Training dataset size},
            ylabel     = {Error},
            xmin       = 0,
            ymin       = 0,
            ymax       = 15,
            height     = 7cm,
            width      = 10cm,
            xtick      = \empty,
            ytick      = \empty,
            black
          ]
          \addplot [
            samples=200,
            domain=0:8,
            blue
          ] {(ln(200*x + 1)/ln(7)) + 6.3};
          \addplot [
            samples=200,
            domain=0.1:8,
            blue
          ] {1/log2(x + 1) + 10};
          \addplot [
            samples=200,
            domain=0:8,
            red
          ] {log2(x + 1)};
          \addplot [
            samples=200,
            domain=0.1:8,
            red
          ] {1/log10(x/2.5 + 1) + 2};

          \draw [black, dashed] (axis cs: 6.5, 0) |- (axis cs: 6.5, 4);
          \draw [black, dashed] (axis cs: 2.5, 0) |- (axis cs: 2.5, 10.6);
          \node [black] at (7.5, 2.2) {$E_{\text{in}}$};
          \node [black] at (7.5, 4.5) {$E_{\text{out}}$};
          \node [black] at (7.5, 9.3) {$E_{\text{in}}$};
          \node [black] at (7.5, 11.3) {$E_{\text{out}}$};
          \node [blue] at (5.3, 11.3) {simple model};
          \node [red] at (5.3, 5) {complex model};
          \node [black] at (3.3, 8) {capacity};
          \node [black] at (5.7, 0.7) {capacity};

        \end{axis}
      \end{tikzpicture}
    \end{figure}
    #+end_export
* Reinforcement learning
  Method where you train the program by rewarding the learning algorithm positively or
  negatively according to the produced results. This method is similar to how we teach
  animals.
* Unsupervised learning
  Given only inputs as training, find a pattern: discover clusters, manifolds, embedding.
